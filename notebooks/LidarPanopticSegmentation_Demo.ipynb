{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiDAR Panoptic Segmentation Demo\n",
    "\n",
    "This notebook demonstrates how to use the LiDAR Panoptic Segmentation system for:\n",
    "1. Configuration and setup\n",
    "2. Installing MinkowskiEngine on Databricks\n",
    "3. Running inference on LiDAR point clouds\n",
    "4. Extracting tree polygons\n",
    "5. MLflow experiment tracking\n",
    "\n",
    "**Prerequisites:**\n",
    "- Azure Databricks 15.4 LTS GPU cluster (single-node)\n",
    "- Unity Catalog access for data storage\n",
    "- Azure DevOps PAT for private MinkowskiEngine repository (if applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up the environment and install MinkowskiEngine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python and PyTorch versions\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA capability: {torch.cuda.get_device_capability(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install MinkowskiEngine (Databricks Only)\n",
    "\n",
    "Run this section only on Databricks GPU clusters. This installs MinkowskiEngine from source with CUDA support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PAT from Azure Key Vault (Databricks secrets)\n",
    "# Uncomment and modify for your secret scope\n",
    "\n",
    "# ADO_PAT = dbutils.secrets.get(\"azure\", \"ado_pat\")\n",
    "# with open(\"/tmp/ado_pat\", \"w\") as f:\n",
    "#     f.write(ADO_PAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MinkowskiEngine from source\n",
    "# This will take several minutes on first run\n",
    "\n",
    "# For private Azure DevOps repo:\n",
    "# %sh\n",
    "# export ADO_PAT=$(cat /tmp/ado_pat)\n",
    "# export ME_REPO=\"https://dev.azure.com/org/project/_git/MinkowskiEngine\"\n",
    "# export ME_REF=\"main\"\n",
    "# bash ./scripts/install_minkowski.sh\n",
    "\n",
    "# For public GitHub repo:\n",
    "# %sh\n",
    "# export ME_REPO=\"https://github.com/NVIDIA/MinkowskiEngine.git\"\n",
    "# export ME_REF=\"master\"\n",
    "# bash ./scripts/install_minkowski.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify MinkowskiEngine installation\n",
    "try:\n",
    "    import MinkowskiEngine as ME\n",
    "    ME.print_diagnostics()\n",
    "    print(\"\\nMinkowskiEngine installed successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"MinkowskiEngine not available: {e}\")\n",
    "    print(\"The system will use fallback mode (not recommended for production)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Load and configure the system using the unified YAML configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidar_panoptic_segmentation.config import load_config, validate_config\n",
    "\n",
    "# Load configuration\n",
    "config = load_config(\"../config.yaml\")\n",
    "\n",
    "# Validate configuration\n",
    "warnings = validate_config(config)\n",
    "if warnings:\n",
    "    print(\"Configuration warnings:\")\n",
    "    for w in warnings:\n",
    "        print(f\"  - {w}\")\n",
    "else:\n",
    "    print(\"Configuration validated successfully!\")\n",
    "\n",
    "print(f\"\\nEnvironment: {config.env.name}\")\n",
    "print(f\"Debug mode: {config.env.debug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override configuration for Databricks\n",
    "overrides = {\n",
    "    \"env\": {\n",
    "        \"name\": \"databricks\",\n",
    "        \"debug\": False,\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"data_root\": \"abfss://forest-data@yourstorageaccount.dfs.core.windows.net/\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Reload with overrides\n",
    "# config = load_config(\"../config.yaml\", overrides=overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model\n",
    "\n",
    "Load a trained model from MLflow registry or local checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidar_panoptic_segmentation.model import create_model, load_model\n",
    "\n",
    "# Create a new model (for demonstration)\n",
    "model = create_model(config)\n",
    "print(f\"Model created: {type(model).__name__}\")\n",
    "print(f\"Number of classes: {model.num_classes}\")\n",
    "print(f\"Embedding dimension: {model.embed_dim}\")\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from MLflow (when available)\n",
    "# model = load_model(\"models:/LidarPanopticSegmentation/latest\")\n",
    "\n",
    "# Or load from local checkpoint\n",
    "# model = load_model(\"./models/checkpoint_best.pt\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading\n",
    "\n",
    "Demonstrate loading point cloud data from Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidar_panoptic_segmentation.dataset import (\n",
    "    read_point_cloud,\n",
    "    CloudStorageHandler,\n",
    "    create_dataloader,\n",
    ")\n",
    "\n",
    "# Example: Read a local point cloud\n",
    "# data = read_point_cloud(\"./sample_data/sample.las\")\n",
    "# print(f\"Loaded {len(data.points)} points\")\n",
    "# print(f\"Bounds: {data.bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic sample data for demonstration\n",
    "import numpy as np\n",
    "\n",
    "n_points = 10000\n",
    "\n",
    "# Create two clusters of points (simulating trees)\n",
    "cluster1 = np.random.randn(n_points // 2, 3).astype(np.float32)\n",
    "cluster1[:, 2] = np.abs(cluster1[:, 2]) * 15  # Trees are tall\n",
    "\n",
    "cluster2 = np.random.randn(n_points // 2, 3).astype(np.float32) + [10, 10, 0]\n",
    "cluster2[:, 2] = np.abs(cluster2[:, 2]) * 12\n",
    "\n",
    "sample_points = np.vstack([cluster1, cluster2])\n",
    "sample_semantic = np.ones(n_points, dtype=np.int64)  # All tree class\n",
    "\n",
    "print(f\"Created sample data: {sample_points.shape}\")\n",
    "print(f\"Point cloud bounds: X=[{sample_points[:, 0].min():.1f}, {sample_points[:, 0].max():.1f}]\")\n",
    "print(f\"                    Y=[{sample_points[:, 1].min():.1f}, {sample_points[:, 1].max():.1f}]\")\n",
    "print(f\"                    Z=[{sample_points[:, 2].min():.1f}, {sample_points[:, 2].max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Inference\n",
    "\n",
    "Process point cloud through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Prepare input tensors\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create batched coordinates (batch_idx, x, y, z)\n",
    "batch_indices = np.zeros((n_points, 1), dtype=np.float32)\n",
    "coords = np.hstack([batch_indices, sample_points]).astype(np.float32)\n",
    "\n",
    "# Create features (xyz + intensity placeholder)\n",
    "intensity = np.random.rand(n_points, 1).astype(np.float32)\n",
    "features = np.hstack([sample_points, intensity]).astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "coords_tensor = torch.from_numpy(coords).to(device)\n",
    "features_tensor = torch.from_numpy(features).to(device)\n",
    "\n",
    "print(f\"Input shapes: coords={coords_tensor.shape}, features={features_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    output = model(coords_tensor, features_tensor)\n",
    "\n",
    "print(f\"Semantic predictions: {output.semantic_pred.shape}\")\n",
    "print(f\"Unique classes: {torch.unique(output.semantic_pred).cpu().numpy()}\")\n",
    "\n",
    "if output.embedding is not None:\n",
    "    print(f\"Embeddings: {output.embedding.shape}\")\n",
    "\n",
    "if output.offset_pred is not None:\n",
    "    print(f\"Offset predictions: {output.offset_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Postprocessing and Polygon Extraction\n",
    "\n",
    "Convert predictions to tree instances and extract polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidar_panoptic_segmentation.postprocess import (\n",
    "    postprocess_predictions,\n",
    "    save_geojson,\n",
    ")\n",
    "\n",
    "# Get predictions as numpy arrays\n",
    "semantic_pred = output.semantic_pred.cpu().numpy()\n",
    "embeddings = output.embedding.cpu().numpy() if output.embedding is not None else None\n",
    "offset_pred = output.offset_pred.cpu().numpy() if output.offset_pred is not None else None\n",
    "\n",
    "# Run postprocessing\n",
    "result = postprocess_predictions(\n",
    "    points=sample_points,\n",
    "    semantic_pred=semantic_pred,\n",
    "    embeddings=embeddings,\n",
    "    offset_pred=offset_pred,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(result.instances)} tree instances\")\n",
    "for inst in result.instances:\n",
    "    print(f\"  Tree {inst.instance_id}: {len(inst.points)} points, height={inst.height:.1f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as GeoJSON\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "output_dir = tempfile.mkdtemp()\n",
    "geojson_path = os.path.join(output_dir, \"trees.geojson\")\n",
    "\n",
    "save_geojson(result.instances, geojson_path)\n",
    "print(f\"Saved GeoJSON to: {geojson_path}\")\n",
    "\n",
    "# Display GeoJSON content\n",
    "import json\n",
    "with open(geojson_path) as f:\n",
    "    geojson_data = json.load(f)\n",
    "    \n",
    "print(f\"\\nGeoJSON contains {len(geojson_data['features'])} features\")\n",
    "if geojson_data['features']:\n",
    "    print(\"\\nSample feature properties:\")\n",
    "    print(json.dumps(geojson_data['features'][0]['properties'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lidar_panoptic_segmentation.utils import colorize_labels, get_color_map\n",
    "\n",
    "# Colorize instance predictions\n",
    "colors = colorize_labels(result.instance_pred)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# XY view with instance colors\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(\n",
    "    result.points[::10, 0],\n",
    "    result.points[::10, 1],\n",
    "    c=colors[::10] / 255.0,\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_title('Point Cloud - XY View (Colored by Instance)')\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# XZ view (side view)\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(\n",
    "    result.points[::10, 0],\n",
    "    result.points[::10, 2],\n",
    "    c=colors[::10] / 255.0,\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Z (Height)')\n",
    "ax2.set_title('Point Cloud - XZ View (Side)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize polygons\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for inst in result.instances:\n",
    "    if inst.polygon is not None:\n",
    "        x, y = inst.polygon.exterior.xy\n",
    "        ax.fill(x, y, alpha=0.3, label=f'Tree {inst.instance_id}')\n",
    "        ax.plot(x, y, linewidth=2)\n",
    "        ax.scatter(*inst.center[:2], marker='x', s=100, c='red')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Extracted Tree Crown Polygons')\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MLflow Integration\n",
    "\n",
    "Track experiments and log models to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidar_panoptic_segmentation.logging_utils import (\n",
    "    MLflowLogger,\n",
    "    experiment_context,\n",
    ")\n",
    "\n",
    "# Example: Log experiment metrics\n",
    "# with experiment_context(config, run_name=\"demo_run\") as exp_logger:\n",
    "#     exp_logger.log_params(config.to_dict())\n",
    "#     exp_logger.log_metrics({\"n_instances\": len(result.instances)})\n",
    "#     exp_logger.log_artifact(geojson_path)\n",
    "#     exp_logger.log_model(model, \"model\")\n",
    "\n",
    "print(\"MLflow integration ready!\")\n",
    "print(f\"Experiment name: {config.logging.mlflow.experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch Processing\n",
    "\n",
    "Process multiple files from Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidar_panoptic_segmentation.infer import InferencePipeline\n",
    "\n",
    "# Create inference pipeline\n",
    "# pipeline = InferencePipeline(config, model=model)\n",
    "\n",
    "# Process a directory\n",
    "# results = pipeline.process_directory(\n",
    "#     input_dir=\"abfss://container@account.dfs.core.windows.net/lidar/\",\n",
    "#     output_dir=\"abfss://container@account.dfs.core.windows.net/predictions/\",\n",
    "# )\n",
    "\n",
    "print(\"Batch processing ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clean up temporary files\n",
    "shutil.rmtree(output_dir, ignore_errors=True)\n",
    "\n",
    "# Clear GPU cache\n",
    "from lidar_panoptic_segmentation.utils import clear_gpu_cache\n",
    "clear_gpu_cache()\n",
    "\n",
    "print(\"Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Environment Setup**: Installing MinkowskiEngine on Databricks\n",
    "2. **Configuration**: Loading YAML config with Pydantic validation\n",
    "3. **Model Loading**: Creating and loading panoptic segmentation models\n",
    "4. **Data Loading**: Reading point clouds from Unity Catalog\n",
    "5. **Inference**: Running predictions on LiDAR data\n",
    "6. **Postprocessing**: Extracting tree instances and polygons\n",
    "7. **Output Formats**: Saving results as GeoJSON\n",
    "8. **MLflow Integration**: Experiment tracking and model registry\n",
    "9. **Batch Processing**: Processing multiple files\n",
    "\n",
    "For more information, see:\n",
    "- `README.md`: Project overview and setup\n",
    "- `cluster_config_guidance.md`: Databricks cluster configuration\n",
    "- `README_Model_Improvements.md`: Model optimization tips"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
